{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a32ad5-9f07-47f2-97ae-15b0646e355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp clinical_tutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db4b759-310c-4e38-9fdc-2efb94b541dd",
   "metadata": {},
   "source": [
    "# Clinical Tutor\n",
    "\n",
    "> Core module for using learning context for context-appropriate tutor responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f93992-88dd-409b-8370-b86302e1ce6a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2403bb-70a1-4744-be0b-d259234c1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ba22b-55c1-467e-8206-a92f88a598fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import aiohttp\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from wardbuddy.learning_context import LearningContext, setup_logger\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "logger = setup_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da445d7-7f51-44d5-b027-e2cf65c79069",
   "metadata": {},
   "source": [
    "## Adaptive Clinical Tutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d76615-480c-4fe4-9d4a-e67dd892132a",
   "metadata": {},
   "source": [
    "This module implements:\n",
    "\n",
    " - Engages in natural case discussions like a clinical supervisor\n",
    " - Provides context-aware feedback based on student's rotation and preferences\n",
    " - Analyzes discussions to track learning progress\n",
    " - Integrates with the student's learning context\n",
    "\n",
    "The tutor aims to mimic real-world clinical teaching interactions where students present cases and receive feedback in a natural conversational style.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d2115-b30f-40ba-9566-bcbaf155026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class OpenRouterException(Exception):\n",
    "    \"\"\"Custom exception for OpenRouter API errors\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2cbfc-75e7-45ee-9d86-b931f81a3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ClinicalTutor:\n",
    "    \"\"\"\n",
    "    Adaptive clinical teaching module that provides context-aware feedback.\n",
    "    \n",
    "    The tutor acts as an experienced clinical supervisor, engaging in natural\n",
    "    case discussions while tracking student progress and adapting feedback\n",
    "    based on learning context.\n",
    "    \n",
    "    Attributes:\n",
    "        learning_context (LearningContext): Student's learning context\n",
    "        model (str): LLM model identifier\n",
    "        api_url (str): OpenRouter API endpoint\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        context_path: Optional[Path] = None,\n",
    "        model: str = \"anthropic/claude-3.5-sonnet\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize clinical tutor.\n",
    "        \n",
    "        Args:\n",
    "            context_path: Optional path for context persistence\n",
    "            model: Model identifier for OpenRouter\n",
    "        \"\"\"\n",
    "        self.api_key: str = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"OpenRouter API key not found\")\n",
    "        \n",
    "        self.api_url: str = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.model: str = model\n",
    "        \n",
    "        self.learning_context = LearningContext(context_path)\n",
    "        self.context_path = context_path\n",
    "        \n",
    "        # Track conversation state\n",
    "        self.current_case: Dict = {\n",
    "            \"started\": None,\n",
    "            \"chief_complaint\": None,\n",
    "            \"key_findings\": [],\n",
    "            \"assessment\": None,\n",
    "            \"plan\": None\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Clinical tutor initialized with model: {model}\")\n",
    "    \n",
    "    async def _get_completion(\n",
    "        self,\n",
    "        messages: List[Dict],\n",
    "        temperature: float = 0.7,\n",
    "        max_retries: int = 3\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Get completion from OpenRouter API with retry logic.\n",
    "        \n",
    "        Args:\n",
    "            messages: List of conversation messages\n",
    "            temperature: Temperature for response generation\n",
    "            max_retries: Maximum retry attempts\n",
    "            \n",
    "        Returns:\n",
    "            str: Model response\n",
    "            \n",
    "        Raises:\n",
    "            OpenRouterException: If API calls fail after retries\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"HTTP-Referer\": \"http://localhost:7860\"\n",
    "        }\n",
    "        \n",
    "        data = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": 2000\n",
    "        }\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                async with aiohttp.ClientSession() as session:\n",
    "                    async with session.post(\n",
    "                        self.api_url,\n",
    "                        headers=headers,\n",
    "                        json=data,\n",
    "                        timeout=30\n",
    "                    ) as response:\n",
    "                        response.raise_for_status()\n",
    "                        result = await response.json()\n",
    "                        return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                        \n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise OpenRouterException(f\"API call failed: {str(e)}\")\n",
    "                logger.warning(f\"Retry {attempt + 1} after error: {str(e)}\")\n",
    "                # Could add exponential backoff here if needed\n",
    "    \n",
    "    def _build_discussion_prompt(self) -> str:\n",
    "        \"\"\"Build context-aware prompt for case discussion.\"\"\"\n",
    "        rotation = self.learning_context.current_rotation\n",
    "        active_preferences = [\n",
    "            p[\"focus\"] for p in self.learning_context.feedback_preferences \n",
    "            if p[\"active\"]\n",
    "        ]\n",
    "        \n",
    "        significant_gaps = {\n",
    "            topic: score for topic, score \n",
    "            in self.learning_context.knowledge_profile[\"gaps\"].items()\n",
    "            if score < 0.7  # Only include significant gaps\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"You are an experienced clinical supervisor in {rotation['specialty']}. Act as an engaging and conversational tutor who coaches towards deeper understanding through Socratic dialogue and targeted questions.\n",
    "\n",
    "        Key Principles:\n",
    "        1. Assume I have strong foundational knowledge in medicine, clinical reasoning, and pre-medical sciences\n",
    "        2. Focus on high-level connections and nuanced clinical decision-making\n",
    "        3. Use targeted questions to explore my thought process and highlight key learning points\n",
    "        4. Share relevant clinical pearls and real-world applications\n",
    "        5. Be conversational and engaging, avoiding lecture-style responses\n",
    "        \n",
    "        Current Rotation Focus Areas:\n",
    "        {', '.join(rotation['key_focus_areas'])}\n",
    "\n",
    "        Areas for Deep Dive:\n",
    "        {', '.join(f'{topic} (confidence: {score:.1f})' for topic, score in significant_gaps.items()) if significant_gaps else 'General clinical reasoning'}\n",
    "\n",
    "        Student's Interests:\n",
    "        {', '.join(active_preferences) if active_preferences else 'Broad clinical discussion'}\n",
    "\n",
    "        Ask probing questions that explore clinical reasoning and highlight important connections. I will ask for clarification \n",
    "        if concepts need more explanation.\"\"\"\n",
    "\n",
    "        return prompt\n",
    "    \n",
    "    def _build_analysis_prompt(self, conversation: List[Dict[str, str]]) -> str:\n",
    "        \"\"\"\n",
    "        Build prompt for post-discussion analysis.\n",
    "        \n",
    "        Args:\n",
    "            conversation: List of message dictionaries with roles and content\n",
    "            \n",
    "        Returns:\n",
    "            str: Analysis prompt\n",
    "        \"\"\"\n",
    "        # Extract case details\n",
    "        case_content = \"\"\n",
    "        for msg in conversation:\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                case_content += msg[\"content\"] + \"\\n\"\n",
    "        \n",
    "        return f\"\"\"Analyze the following case discussion between a medical student and \n",
    "        clinical supervisor. Focus on the student's demonstrated knowledge, skills, \n",
    "        and areas for improvement.\n",
    "\n",
    "        Case Content:\n",
    "        {case_content}\n",
    "\n",
    "        Please identify:\n",
    "        1. Key clinical concepts and learning points demonstrated or discussed\n",
    "        2. Areas where the student showed uncertainty or knowledge gaps\n",
    "        3. Strengths demonstrated in clinical reasoning and presentation\n",
    "        4. Specific learning objectives that would help the student's development\n",
    "\n",
    "        Frame your response to help with ongoing learning:\n",
    "        - Start with positive observations\n",
    "        - Be specific about knowledge gaps\n",
    "        - Make concrete suggestions for improvement\n",
    "        - Connect to practical clinical scenarios\"\"\"\n",
    "    \n",
    "    async def discuss_case(\n",
    "        self, \n",
    "        message: str,\n",
    "        temperature: float = 0.7\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Natural case discussion with context-aware responses.\n",
    "        \n",
    "        Args:\n",
    "            message: Student's input message\n",
    "            temperature: Temperature for response generation\n",
    "            \n",
    "        Returns:\n",
    "            str: Clinical supervisor's response\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Update case tracking\n",
    "            if not self.current_case[\"started\"]:\n",
    "                self.current_case[\"started\"] = datetime.now()\n",
    "                # Try to identify chief complaint from first message\n",
    "                cc_match = re.search(r\"(\\d+)\\s*[yY][oO]\\s*[MmFf]\\s*with\\s*([^.]*)\", message)\n",
    "                if cc_match:\n",
    "                    self.current_case[\"chief_complaint\"] = cc_match.group(2).strip()\n",
    "            \n",
    "            # Build system prompt\n",
    "            system_prompt = self._build_discussion_prompt()\n",
    "            \n",
    "            messages = [{\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            }, {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message\n",
    "            }]\n",
    "            \n",
    "            response = await self._get_completion(messages, temperature)\n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in case discussion: {str(e)}\")\n",
    "            return \"I apologize, but I encountered an error. Please try presenting your case again.\"\n",
    "    \n",
    "    async def analyze_discussion(\n",
    "        self,\n",
    "        conversation: List[Dict[str, str]]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze completed case discussion for learning insights.\n",
    "        \n",
    "        Args:\n",
    "            conversation: List of message dictionaries with roles and content\n",
    "            \n",
    "        Returns:\n",
    "            dict: Analysis results containing:\n",
    "                - learning_points: List of key concepts learned\n",
    "                - gaps: Dict of identified knowledge gaps\n",
    "                - strengths: List of demonstrated strengths\n",
    "                - suggested_objectives: List of recommended learning goals\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Reset case tracking\n",
    "            self.current_case = {\n",
    "                \"started\": None,\n",
    "                \"chief_complaint\": None,\n",
    "                \"key_findings\": [],\n",
    "                \"assessment\": None,\n",
    "                \"plan\": None\n",
    "            }\n",
    "            \n",
    "            # Get analysis from model\n",
    "            analysis_prompt = self._build_analysis_prompt(conversation)\n",
    "            messages = [{\n",
    "                \"role\": \"system\",\n",
    "                \"content\": analysis_prompt\n",
    "            }]\n",
    "            messages.extend(conversation)\n",
    "            \n",
    "            response = await self._get_completion(messages, temperature=0.3)\n",
    "            \n",
    "            # Parse insights\n",
    "            insights = self._parse_analysis(response)\n",
    "            \n",
    "            # Update learning context\n",
    "            self._update_context_from_analysis(insights)\n",
    "            \n",
    "            return insights\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in discussion analysis: {str(e)}\")\n",
    "            return {\n",
    "                \"learning_points\": [],\n",
    "                \"gaps\": {},\n",
    "                \"strengths\": [],\n",
    "                \"suggested_objectives\": []\n",
    "            }\n",
    "    \n",
    "    def _parse_analysis(self, response: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Parse analysis response into structured insights.\n",
    "        \n",
    "        Uses pattern matching and basic NLP to extract:\n",
    "        - Learning points (key concepts discussed)\n",
    "        - Knowledge gaps with confidence estimates\n",
    "        - Demonstrated strengths\n",
    "        - Suggested learning objectives\n",
    "        \n",
    "        Args:\n",
    "            response: Raw analysis response\n",
    "            \n",
    "        Returns:\n",
    "            dict: Structured analysis insights\n",
    "        \"\"\"\n",
    "        insights = {\n",
    "            \"learning_points\": [],\n",
    "            \"gaps\": {},\n",
    "            \"strengths\": [],\n",
    "            \"suggested_objectives\": []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Split into sections\n",
    "            sections = response.lower().split(\"\\n\\n\")\n",
    "            \n",
    "            for section in sections:\n",
    "                if \"learning point\" in section or \"key concept\" in section:\n",
    "                    # Extract bullet points or numbered items\n",
    "                    points = re.findall(r\"[-•*]\\s*(.+)$\", section, re.MULTILINE)\n",
    "                    insights[\"learning_points\"].extend(points)\n",
    "                    \n",
    "                elif \"gap\" in section or \"uncertainty\" in section:\n",
    "                    # Look for topic mentions with confidence indicators\n",
    "                    gaps = re.findall(\n",
    "                        r\"(limited|uncertain|unclear|difficulty with)\\s+([^,.]+)\", \n",
    "                        section\n",
    "                    )\n",
    "                    for indicator, topic in gaps:\n",
    "                        # Estimate confidence based on language\n",
    "                        confidence = 0.4 if \"limited\" in indicator else 0.6\n",
    "                        insights[\"gaps\"][topic.strip()] = confidence\n",
    "                        \n",
    "                elif \"strength\" in section or \"demonstrated\" in section:\n",
    "                    # Extract positive mentions\n",
    "                    strengths = re.findall(r\"[-•*]\\s*(.+)$\", section, re.MULTILINE)\n",
    "                    insights[\"strengths\"].extend(strengths)\n",
    "                    \n",
    "                elif \"objective\" in section or \"suggest\" in section:\n",
    "                    # Extract recommended objectives\n",
    "                    objectives = re.findall(r\"[-•*]\\s*(.+)$\", section, re.MULTILINE)\n",
    "                    insights[\"suggested_objectives\"].extend(objectives)\n",
    "            \n",
    "            return insights\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing analysis: {str(e)}\")\n",
    "            return insights\n",
    "    \n",
    "    def _update_context_from_analysis(self, insights: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Update learning context based on discussion analysis.\n",
    "        \n",
    "        Args:\n",
    "            insights: Dictionary of analysis insights\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Update knowledge gaps\n",
    "            for topic, confidence in insights[\"gaps\"].items():\n",
    "                self.learning_context.update_knowledge_gap(topic, confidence)\n",
    "            \n",
    "            # Add strengths\n",
    "            for strength in insights[\"strengths\"]:\n",
    "                self.learning_context.add_strength(strength)\n",
    "            \n",
    "            # Save context if path provided\n",
    "            if self.context_path:\n",
    "                self.learning_context.save_context(self.context_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error updating context: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b15f5-6841-43cb-9b57-c0e3f1a0b0c2",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee6bde-4ade-448e-a831-86f9f7ae82ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_clinical_tutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "async def test_clinical_tutor():\n",
    "    \"\"\"Test ClinicalTutor functionality\"\"\"\n",
    "    if not os.getenv(\"OPENROUTER_API_KEY\"):\n",
    "        print(\"Skipping tests: No API key\")\n",
    "        return\n",
    "        \n",
    "    tutor = ClinicalTutor()\n",
    "    \n",
    "    # Test case discussion\n",
    "    test_case = \"\"\"\n",
    "    28yo M with chest pain\n",
    "    - 2 days duration\n",
    "    - Sharp, pleuritic\n",
    "    - No fever or cough\n",
    "    - Vitals stable\n",
    "    - Clear exam\n",
    "    A/P: Likely MSK pain\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Test basic discussion\n",
    "        response = await tutor.discuss_case(test_case)\n",
    "        assert isinstance(response, str)\n",
    "        assert len(response) > 0\n",
    "        \n",
    "        # Only assert case tracking if chief complaint was detected\n",
    "        if tutor.current_case[\"chief_complaint\"]:\n",
    "            assert \"chest pain\" in tutor.current_case[\"chief_complaint\"].lower()\n",
    "        \n",
    "        print(\"Discussion test passed\")\n",
    "        \n",
    "        # Test discussion analysis\n",
    "        conversation = [\n",
    "            {\"role\": \"user\", \"content\": test_case},\n",
    "            {\"role\": \"assistant\", \"content\": response}\n",
    "        ]\n",
    "        \n",
    "        analysis = await tutor.analyze_discussion(conversation)\n",
    "        assert isinstance(analysis, dict)\n",
    "        assert all(k in analysis for k in [\n",
    "            'learning_points', 'gaps', 'strengths', 'suggested_objectives'\n",
    "        ])\n",
    "        print(\"Analysis test passed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Test failed: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    print(\"All clinical tutor tests passed!\")\n",
    "\n",
    "# Run tests\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    if not asyncio.get_event_loop().is_running():\n",
    "        asyncio.run(test_clinical_tutor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f469c37-afe3-4682-9cc4-40326ac21b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
